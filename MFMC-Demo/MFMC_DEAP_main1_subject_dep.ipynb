{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFMC Demo for DEAP Dataset - Tri-modal Emotion Recognition\n",
    "# Multi-modal Feature Matching and Correlation (MFMC) approach\n",
    "# Modalities: EEG, EOG, Temperature signals\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(\"MFMC Demo for DEAP Dataset\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPERIMENT CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Define base paths\n",
    "BASE_PATH = 'MFMC-Demo'\n",
    "DATA_DIR = f'{BASE_PATH}/Data_processed'\n",
    "RESULTS_DIR = f'{BASE_PATH}/subject_dependent_results'\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 200\n",
    "TOTAL_ITERATIONS = 20001  # 15001 for test, 20001 for full training\n",
    "EVAL_INTERVAL = 500       # Evaluate every 500 iterations\n",
    "\n",
    "# Cross-validation parameters\n",
    "N_FOLDS = 5              # Number of cross-validation folds\n",
    "RANDOM_SEED = 42         # For reproducible results\n",
    "\n",
    "# Optimizer parameters\n",
    "LEARNING_RATE_ENCODER = 0.0003\n",
    "LEARNING_RATE_CLASSIFIER = 0.0003\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "\n",
    "# MFMC parameters\n",
    "COV_BETA = 0.5           # Exponential moving average coefficient for covariance tracking\n",
    "\n",
    "# Data preprocessing parameters\n",
    "USE_CLASS_BALANCING = False        # Class-weighted loss for imbalanced data\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"Total iterations: {TOTAL_ITERATIONS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MFMC LOSS FUNCTIONS AND PROJECTION HEAD\n",
    "# =============================================================================\n",
    "\n",
    "def adaptive_estimation(v_t, beta, square_term, i):\n",
    "    \"\"\"\n",
    "    Adaptive smoothing filter for estimating covariances\n",
    "    \n",
    "    Args:\n",
    "        v_t: Previous covariance estimate\n",
    "        beta: Exponential moving average coefficient\n",
    "        square_term: Current covariance matrix\n",
    "        i: Current iteration number\n",
    "    \n",
    "    Returns:\n",
    "        Updated covariance estimate and bias-corrected estimate\n",
    "    \"\"\"\n",
    "    v_t = beta * v_t + (1 - beta) * square_term.detach()\n",
    "    return v_t, (v_t / (1 - beta ** i))\n",
    "\n",
    "def MFMC_t_trace(x, y, track_cov, i, cov_beta=0.95):\n",
    "    \"\"\"\n",
    "    Compute MFMC-T trace loss for a single pair of feature matrices\n",
    "    \n",
    "    This function implements the core MFMC trace loss that maximizes\n",
    "    the correlation between features from different modalities.\n",
    "    \n",
    "    Args:\n",
    "        x: Feature matrix from first modality [batch_size, feature_dim]\n",
    "        y: Feature matrix from second modality [batch_size, feature_dim]\n",
    "        track_cov: Dictionary containing tracking variables for covariances\n",
    "        i: Current iteration number\n",
    "        cov_beta: Exponential moving average coefficient for covariance tracking\n",
    "    \n",
    "    Returns:\n",
    "        track_cov: Updated tracking dictionary\n",
    "        loss: MFMC-T trace loss value\n",
    "    \"\"\"\n",
    "    # Calculate auto-covariances and cross-covariance\n",
    "    Rx = (x.T @ x) / x.shape[0]\n",
    "    Ry = (y.T @ y) / y.shape[0]\n",
    "    Pxy = (x.T @ y) / x.shape[0]\n",
    "    \n",
    "    # Add small epsilon for numerical stability\n",
    "    eps = 1e-6\n",
    "    Rx = Rx + torch.eye(Rx.shape[0]).to(Rx.device) * eps\n",
    "    Ry = Ry + torch.eye(Ry.shape[0]).to(Ry.device) * eps\n",
    "    \n",
    "    # Update tracking estimates using adaptive estimation\n",
    "    track_cov['Rx'], Rx_est = adaptive_estimation(track_cov['Rx'], cov_beta, Rx, i)\n",
    "    track_cov['Ry'], Ry_est = adaptive_estimation(track_cov['Ry'], cov_beta, Ry, i)\n",
    "    track_cov['Pxy'], Pxy_est = adaptive_estimation(track_cov['Pxy'], cov_beta, Pxy, i)\n",
    "    \n",
    "    # Compute matrix inverses\n",
    "    Rx_est_inv = torch.inverse(Rx_est)\n",
    "    Ry_est_inv = torch.inverse(Ry_est)\n",
    "    \n",
    "    # Compute MFMC-T trace cost (maximizes cross-modal correlation)\n",
    "    cost = -Rx_est_inv @ Rx @ Rx_est_inv @ Pxy_est @ Ry_est_inv @ Pxy_est.T \\\n",
    "           + Rx_est_inv @ Pxy @ Ry_est_inv @ Pxy_est.T \\\n",
    "           - Rx_est_inv @ Pxy_est @ Ry_est_inv @ Ry @ Ry_est_inv @ Pxy_est.T \\\n",
    "           + Rx_est_inv @ Pxy_est @ Ry_est_inv @ Pxy.T\n",
    "    \n",
    "    # Return negative trace as the loss (to minimize)\n",
    "    loss = -torch.trace(cost)\n",
    "    \n",
    "    return track_cov, loss\n",
    "\n",
    "def tri_modal_projection_loss(fe1, fe2, fe3, proj12, proj23, proj13, trackers, step, cov_beta=0.5):\n",
    "    \"\"\"\n",
    "    Compute the tri-modal projection loss for MFMC\n",
    "    \n",
    "    The loss function is: L = MFMC(E1, P23(E2⊕E3)) + MFMC(E2, P13(E1⊕E3)) + MFMC(E3, P12(E1⊕E2))\n",
    "    \n",
    "    This creates three pairwise correlations:\n",
    "    - EEG features with projected EOG+TEMP features\n",
    "    - EOG features with projected EEG+TEMP features  \n",
    "    - TEMP features with projected EEG+EOG features\n",
    "    \n",
    "    Args:\n",
    "        fe1: EEG features [batch_size, 128]\n",
    "        fe2: EOG features [batch_size, 128]\n",
    "        fe3: TEMP features [batch_size, 128]\n",
    "        proj12: Projection head for E1⊕E2 → 128D\n",
    "        proj23: Projection head for E2⊕E3 → 128D\n",
    "        proj13: Projection head for E1⊕E3 → 128D\n",
    "        trackers: Dictionary containing three covariance trackers\n",
    "        step: Current iteration number\n",
    "        cov_beta: Exponential moving average coefficient for covariance tracking\n",
    "    \n",
    "    Returns:\n",
    "        trackers: Updated covariance trackers\n",
    "        total_loss: Sum of three MFMC-T losses\n",
    "    \"\"\"\n",
    "    # Concatenate features for projection (256D input for each projection head)\n",
    "    concat_12 = torch.cat([fe1, fe2], dim=1)  # EEG + EOG → [batch_size, 256]\n",
    "    concat_23 = torch.cat([fe2, fe3], dim=1)  # EOG + TEMP → [batch_size, 256]\n",
    "    concat_13 = torch.cat([fe1, fe3], dim=1)  # EEG + TEMP → [batch_size, 256]\n",
    "    \n",
    "    # Apply projection heads to get 128D representations\n",
    "    proj_12 = proj12(concat_12)  # [batch_size, 128]\n",
    "    proj_23 = proj23(concat_23)  # [batch_size, 128]\n",
    "    proj_13 = proj13(concat_13)  # [batch_size, 128]\n",
    "    \n",
    "    # Compute MFMC losses for each modality pairing\n",
    "    # Loss 1: MFMC(EEG, P23(EOG⊕TEMP))\n",
    "    trackers['track_1_23'], loss1 = MFMC_t_trace(fe1, proj_23, trackers['track_1_23'], step, cov_beta)\n",
    "    \n",
    "    # Loss 2: MFMC(EOG, P13(EEG⊕TEMP))\n",
    "    trackers['track_2_13'], loss2 = MFMC_t_trace(fe2, proj_13, trackers['track_2_13'], step, cov_beta)\n",
    "    \n",
    "    # Loss 3: MFMC(TEMP, P12(EEG⊕EOG))\n",
    "    trackers['track_3_12'], loss3 = MFMC_t_trace(fe3, proj_12, trackers['track_3_12'], step, cov_beta)\n",
    "    \n",
    "    # Total tri-modal loss\n",
    "    total_loss = loss1 + loss2 + loss3\n",
    "    \n",
    "    return trackers, total_loss\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    2-layer MLP projection head for MFMC\n",
    "    \n",
    "    Architecture: Linear(256→512) + BN + ReLU → Linear(512→128) + BN\n",
    "    \n",
    "    Takes concatenated features from two modalities (256D) and projects\n",
    "    to a common 128D representation space for correlation computation.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=256, hidden_dim=512, output_dim=128):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "print(\"MFMC loss functions and projection head defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NEURAL NETWORK ARCHITECTURES\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "class NETWORK_F_MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer perceptron for feature transformation\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=784, hidden_dim=200, out_dim=200, num_layers=2):\n",
    "        super(NETWORK_F_MLP, self).__init__()\n",
    "        self.dim = out_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.fc_list = []\n",
    "        self.bn_list = []\n",
    "        \n",
    "        # First layer\n",
    "        self.fc_list.append(nn.Linear(input_dim, hidden_dim, bias=True))\n",
    "        self.bn_list.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(self.num_layers - 1):\n",
    "            self.fc_list.append(nn.Linear(hidden_dim, hidden_dim, bias=True))\n",
    "            self.bn_list.append(nn.BatchNorm1d(hidden_dim))\n",
    "            \n",
    "        self.fc_list = nn.ModuleList(self.fc_list)\n",
    "        self.bn_list = nn.ModuleList(self.bn_list)\n",
    "\n",
    "        # Final layer\n",
    "        self.fc_final = nn.Linear(hidden_dim, out_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.fc_list[i](x)\n",
    "            x = torch.relu(x)\n",
    "            x = self.bn_list[i](x)\n",
    "        \n",
    "        x = self.fc_final(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class Advanced1DCNN_channel(nn.Module):\n",
    "    \"\"\"\n",
    "    Advanced 1D CNN for processing physiological signals\n",
    "    \n",
    "    This network processes multi-channel time series data (EEG, EOG, Temperature)\n",
    "    and extracts meaningful features for emotion recognition.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, num_classes=128, input_size=1280):\n",
    "        super(Advanced1DCNN_channel, self).__init__()\n",
    "        \n",
    "        # Convolutional layers with increasing depth\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=11, padding=5),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=11, padding=5),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=11, padding=5),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=11, padding=5),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "\n",
    "        # Calculate feature size after convolutions\n",
    "        feat_size = input_size // (4 * 4 * 4 * 4)  # 4 max-pooling layers\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256 * feat_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Multi-layer perceptron for final feature processing\n",
    "        self.MLP = NETWORK_F_MLP(\n",
    "            input_dim=128 * input_channels, \n",
    "            hidden_dim=4000, \n",
    "            out_dim=num_classes, \n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, channels = x.shape[0], x.shape[1]\n",
    "        \n",
    "        # Process each channel separately through CNN\n",
    "        x = x.unsqueeze(2)  # Add temporal dimension\n",
    "        x = x.flatten(0, 1)  # Combine batch and channel dimensions\n",
    "        \n",
    "        # Convolutional feature extraction\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        \n",
    "        # Flatten and process through FC layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        # Reshape and process through MLP\n",
    "        out = out.reshape(batch_size, channels, -1)\n",
    "        out = out.flatten(-2, -1)\n",
    "        out = self.MLP(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ComplexClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer classifier for emotion recognition\n",
    "    \n",
    "    Takes 128D features from any modality and predicts emotion class.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_features=128, num_classes=4):\n",
    "        super(ComplexClassifier, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(dim_features, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.fc4(x)  # No activation - CrossEntropyLoss includes softmax\n",
    "        return x\n",
    "\n",
    "print(\"Neural network architectures defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07903602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Loading DEAP dataset...\")\n",
    "print(\"Dataset contains physiological signals for emotion recognition:\")\n",
    "print(\"- EEG: Electroencephalography (brain activity)\")\n",
    "print(\"- EOG: Electrooculography (eye movement)\")\n",
    "print(\"- Temperature: Skin temperature\")\n",
    "print(\"- Emotion labels: 4 classes based on valence-arousal model\")\n",
    "\n",
    "try:\n",
    "    # Load preprocessed DEAP data\n",
    "    print(f\"Loading data from: {DATA_DIR}\")\n",
    "    \n",
    "    subject = np.load(f'{DATA_DIR}/subject.npy')\n",
    "    emotion_labels = np.load(f'{DATA_DIR}/emotion_labels.npy')\n",
    "    eeg_data = np.load(f'{DATA_DIR}/eeg_data.npy')\n",
    "    eog_data = np.load(f'{DATA_DIR}/eog_data.npy')\n",
    "    temp_data = np.load(f'{DATA_DIR}/temp_data.npy')\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    subject = torch.from_numpy(subject).long()\n",
    "    emotion_labels = torch.from_numpy(emotion_labels).long()\n",
    "    eeg_data = torch.from_numpy(eeg_data).float()\n",
    "    eog_data = torch.from_numpy(eog_data).float()\n",
    "    temp_data = torch.from_numpy(temp_data).float()\n",
    "    \n",
    "    print(\"\\\\nData loaded successfully!\")\n",
    "    print(f\"Dataset statistics:\")\n",
    "    print(f\"- Total samples: {eeg_data.shape[0]}\")\n",
    "    print(f\"- EEG shape: {eeg_data.shape} (samples, channels, time_points)\")\n",
    "    print(f\"- EOG shape: {eog_data.shape}\")\n",
    "    print(f\"- Temperature shape: {temp_data.shape}\")\n",
    "    print(f\"- Emotion labels shape: {emotion_labels.shape}\")\n",
    "    print(f\"- Number of unique subjects: {len(torch.unique(subject))}\")\n",
    "    print(f\"- Number of emotion classes: {len(torch.unique(emotion_labels))}\")\n",
    "    \n",
    "    # Display emotion class distribution\n",
    "    class_counts = torch.bincount(emotion_labels)\n",
    "    quadrant_names = [\"Low V-Low A (Sad)\", \"Low V-High A (Angry)\", \n",
    "                     \"High V-Low A (Calm)\", \"High V-High A (Happy)\"]\n",
    "    \n",
    "    print(f\"\\\\nEmotion class distribution:\")\n",
    "    for i, (name, count) in enumerate(zip(quadrant_names, class_counts)):\n",
    "        print(f\"  Class {i} - {name}: {count} samples ({count/len(emotion_labels)*100:.1f}%)\")\n",
    "    \n",
    "    # Prepare data for 5-fold cross-validation\n",
    "    print(f\"\\\\nPreparing data for {N_FOLDS}-fold cross-validation...\")\n",
    "    indices = np.arange(eeg_data.shape[0])\n",
    "    \n",
    "    # Create stratified K-fold splits\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Store fold information\n",
    "    fold_splits = []\n",
    "    for fold_idx, (train_indices, test_indices) in enumerate(skf.split(indices, emotion_labels)):\n",
    "        fold_splits.append({\n",
    "            'fold': fold_idx + 1,\n",
    "            'train_indices': train_indices,\n",
    "            'test_indices': test_indices,\n",
    "            'train_size': len(train_indices),\n",
    "            'test_size': len(test_indices)\n",
    "        })\n",
    "        print(f\"Fold {fold_idx + 1}: Train={len(train_indices)}, Test={len(test_indices)}\")\n",
    "    \n",
    "    print(f\"\\\\n5-fold cross-validation setup complete!\")\n",
    "    print(f\"Each fold will be trained for {TOTAL_ITERATIONS} iterations\")\n",
    "    \n",
    "    data_loaded = True\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\" Error loading data: {e}\")\n",
    "    print(\"Please ensure the DEAP dataset is preprocessed and available at the specified path.\")\n",
    "    data_loaded = False\n",
    "except Exception as e:\n",
    "    print(f\" Unexpected error: {e}\")\n",
    "    data_loaded = False\n",
    "\n",
    "if data_loaded:\n",
    "    print(\"\\\\n Data loading and preprocessing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL INITIALIZATION AND TRAINING SETUP\n",
    "# =============================================================================\n",
    "\n",
    "if data_loaded:\n",
    "    print(\"Initializing MFMC models and training components...\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize feature extraction networks for each modality\n",
    "    print(\"\\\\nInitializing feature extraction networks:\")\n",
    "    \n",
    "    # EEG feature extractor\n",
    "    NET_EEG = Advanced1DCNN_channel(\n",
    "        input_channels=eeg_data.shape[1], \n",
    "        num_classes=128, \n",
    "        input_size=eeg_data.shape[2]\n",
    "    ).to(device)\n",
    "    print(f\"- EEG Network: {eeg_data.shape[1]} channels → 128D features\")\n",
    "    \n",
    "    # EOG feature extractor\n",
    "    NET_EOG = Advanced1DCNN_channel(\n",
    "        input_channels=eog_data.shape[1], \n",
    "        num_classes=128, \n",
    "        input_size=eog_data.shape[2]\n",
    "    ).to(device)\n",
    "    print(f\"- EOG Network: {eog_data.shape[1]} channels → 128D features\")\n",
    "    \n",
    "    # Temperature feature extractor\n",
    "    NET_TEMP = Advanced1DCNN_channel(\n",
    "        input_channels=temp_data.shape[1], \n",
    "        num_classes=128, \n",
    "        input_size=temp_data.shape[2]\n",
    "    ).to(device)\n",
    "    print(f\"- Temperature Network: {temp_data.shape[1]} channels → 128D features\")\n",
    "    \n",
    "    # Initialize projection heads for MFMC tri-modal loss\n",
    "    print(\"\\\\nInitializing MFMC projection heads:\")\n",
    "    proj_12 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)  # EEG + EOG\n",
    "    proj_23 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)  # EOG + TEMP\n",
    "    proj_13 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)  # EEG + TEMP\n",
    "    print(\"Projection heads initialized for tri-modal loss\")\n",
    "    \n",
    "    # Initialize emotion classifier\n",
    "    num_classes = len(torch.unique(emotion_labels))\n",
    "    classifier = ComplexClassifier(dim_features=128, num_classes=num_classes).to(device)\n",
    "    print(f\"\\\\nEmotion classifier: 128D features → {num_classes} emotion classes\")\n",
    "    \n",
    "    # Initialize loss function\n",
    "    if USE_CLASS_BALANCING and class_weights is not None:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "        print(\"Using class-weighted CrossEntropy loss\")\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(\"Using standard CrossEntropy loss\")\n",
    "    \n",
    "    # Setup optimizers\n",
    "    print(\"\\\\nSetting up optimizers:\")\n",
    "    \n",
    "    # Feature extractor optimizer (includes all encoders and projection heads)\n",
    "    all_feature_params = (list(NET_EEG.parameters()) + list(NET_EOG.parameters()) + \n",
    "                         list(NET_TEMP.parameters()) + list(proj_12.parameters()) + \n",
    "                         list(proj_23.parameters()) + list(proj_13.parameters()))\n",
    "    \n",
    "    optimizer_features = optim.Adam(\n",
    "        all_feature_params, \n",
    "        lr=LEARNING_RATE_ENCODER, \n",
    "        betas=(BETA1, BETA2), \n",
    "        amsgrad=True\n",
    "    )\n",
    "    print(f\"- Feature extractor optimizer: Adam (lr={LEARNING_RATE_ENCODER})\")\n",
    "    \n",
    "    # Classifier optimizer\n",
    "    optimizer_classifier = optim.Adam(\n",
    "        classifier.parameters(), \n",
    "        lr=LEARNING_RATE_CLASSIFIER, \n",
    "        betas=(BETA1, BETA2), \n",
    "        amsgrad=True\n",
    "    )\n",
    "    print(f\"- Classifier optimizer: Adam (lr={LEARNING_RATE_CLASSIFIER})\")\n",
    "    \n",
    "    # Initialize covariance tracking for MFMC tri-modal loss\n",
    "    print(\"\\\\nInitializing MFMC covariance trackers:\")\n",
    "    feature_dim = 128\n",
    "    trackers = {\n",
    "        'track_1_23': {  # EEG vs EOG+TEMP projection\n",
    "            'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Pxy': torch.zeros(feature_dim, feature_dim).to(device)\n",
    "        },\n",
    "        'track_2_13': {  # EOG vs EEG+TEMP projection\n",
    "            'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Pxy': torch.zeros(feature_dim, feature_dim).to(device)\n",
    "        },\n",
    "        'track_3_12': {  # TEMP vs EEG+EOG projection\n",
    "            'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Pxy': torch.zeros(feature_dim, feature_dim).to(device)\n",
    "        }\n",
    "    }\n",
    "    print(\"Covariance trackers initialized for tri-modal loss\")\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    costs = []\n",
    "    classifier_losses = []\n",
    "    test_accuracies = []\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    print(f\"\\\\nModel initialization complete!\")\n",
    "    print(f\"Ready to start MFMC training with two-phase strategy:\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot initialize models - data loading failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5-FOLD CROSS-VALIDATION MFMC TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "if data_loaded:\n",
    "    print(\"Starting 5-fold cross-validation MFMC training...\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TRAINING STRATEGY:\")\n",
    "    print(\"Phase 1: UNSUPERVISED encoder training with MFMC tri-modal loss\")\n",
    "    print(\"Phase 2: SUPERVISED classifier training with CrossEntropy loss\")\n",
    "    print(f\"Cross-validation: {N_FOLDS} folds, {TOTAL_ITERATIONS} iterations per fold\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Store results across all folds\n",
    "    fold_results = []\n",
    "    all_fold_costs = []\n",
    "    all_fold_classifier_losses = []\n",
    "    all_fold_test_accuracies = []\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    total_cv_start_time = time.time()\n",
    "    \n",
    "    # Start cross-validation\n",
    "    for fold_idx, fold_info in enumerate(fold_splits):\n",
    "        fold_num = fold_info['fold']\n",
    "        train_indices = fold_info['train_indices'] \n",
    "        test_indices = fold_info['test_indices']\n",
    "        \n",
    "        print(f\"\\\\n{'='*60}\")\n",
    "        print(f\"FOLD {fold_num}/{N_FOLDS}\")\n",
    "        print(f\"Train samples: {len(train_indices)}, Test samples: {len(test_indices)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create fold-specific train/test splits\n",
    "        train_eeg = eeg_data[train_indices]\n",
    "        test_eeg = eeg_data[test_indices]\n",
    "        train_eog = eog_data[train_indices]\n",
    "        test_eog = eog_data[test_indices]\n",
    "        train_temp = temp_data[train_indices]\n",
    "        test_temp = temp_data[test_indices]\n",
    "        train_labels = emotion_labels[train_indices]\n",
    "        test_labels = emotion_labels[test_indices]\n",
    "        \n",
    "        # Compute class weights for this fold\n",
    "        train_class_counts = torch.bincount(train_labels)\n",
    "        if USE_CLASS_BALANCING:\n",
    "            class_weights = 1.0 / train_class_counts.float()\n",
    "            class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
    "            criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Initialize models for this fold\n",
    "        NET_EEG = Advanced1DCNN_channel(\n",
    "            input_channels=eeg_data.shape[1], num_classes=128, input_size=eeg_data.shape[2]\n",
    "        ).to(device)\n",
    "        NET_EOG = Advanced1DCNN_channel(\n",
    "            input_channels=eog_data.shape[1], num_classes=128, input_size=eog_data.shape[2]\n",
    "        ).to(device)\n",
    "        NET_TEMP = Advanced1DCNN_channel(\n",
    "            input_channels=temp_data.shape[1], num_classes=128, input_size=temp_data.shape[2]\n",
    "        ).to(device)\n",
    "        \n",
    "        proj_12 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)\n",
    "        proj_23 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)\n",
    "        proj_13 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)\n",
    "        \n",
    "        num_classes = len(torch.unique(emotion_labels))\n",
    "        classifier = ComplexClassifier(dim_features=128, num_classes=num_classes).to(device)\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        all_feature_params = (list(NET_EEG.parameters()) + list(NET_EOG.parameters()) + \n",
    "                             list(NET_TEMP.parameters()) + list(proj_12.parameters()) + \n",
    "                             list(proj_23.parameters()) + list(proj_13.parameters()))\n",
    "        \n",
    "        optimizer_features = optim.Adam(all_feature_params, lr=LEARNING_RATE_ENCODER, \n",
    "                                       betas=(BETA1, BETA2), amsgrad=True)\n",
    "        optimizer_classifier = optim.Adam(classifier.parameters(), lr=LEARNING_RATE_CLASSIFIER, \n",
    "                                         betas=(BETA1, BETA2), amsgrad=True)\n",
    "        \n",
    "        # Initialize covariance trackers\n",
    "        feature_dim = 128\n",
    "        trackers = {\n",
    "            'track_1_23': {'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Pxy': torch.zeros(feature_dim, feature_dim).to(device)},\n",
    "            'track_2_13': {'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Pxy': torch.zeros(feature_dim, feature_dim).to(device)},\n",
    "            'track_3_12': {'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Pxy': torch.zeros(feature_dim, feature_dim).to(device)}\n",
    "        }\n",
    "        \n",
    "        # Initialize tracking for this fold\n",
    "        fold_costs = []\n",
    "        fold_classifier_losses = []\n",
    "        fold_test_accuracies = []\n",
    "        fold_best_accuracy = 0.0\n",
    "        \n",
    "        fold_start_time = time.time()\n",
    "        \n",
    "        # Training loop for this fold\n",
    "        for iteration in range(1, TOTAL_ITERATIONS):\n",
    "            # =====================================================================\n",
    "            # PHASE 1: UNSUPERVISED ENCODER TRAINING (MFMC Loss Only)\n",
    "            # =====================================================================\n",
    "            optimizer_features.zero_grad()\n",
    "            \n",
    "            batch_indices = torch.randint(0, len(train_eeg), (BATCH_SIZE,))\n",
    "            \n",
    "            input_eeg = train_eeg[batch_indices].to(device)\n",
    "            input_eog = train_eog[batch_indices].to(device)\n",
    "            input_temp = train_temp[batch_indices].to(device)\n",
    "            \n",
    "            feature_eeg = NET_EEG(input_eeg)\n",
    "            feature_eog = NET_EOG(input_eog)\n",
    "            feature_temp = NET_TEMP(input_temp)\n",
    "            \n",
    "            trackers, mfmc_loss = tri_modal_projection_loss(\n",
    "                feature_eeg, feature_eog, feature_temp,\n",
    "                proj_12, proj_23, proj_13, trackers, iteration, COV_BETA\n",
    "            )\n",
    "            \n",
    "            mfmc_loss.backward()\n",
    "            optimizer_features.step()\n",
    "            \n",
    "            # =====================================================================\n",
    "            # PHASE 2: SUPERVISED CLASSIFIER TRAINING (CrossEntropy Loss Only)\n",
    "            # =====================================================================\n",
    "            optimizer_classifier.zero_grad()\n",
    "            \n",
    "            batch_indices = torch.randint(0, len(train_eeg), (BATCH_SIZE,))\n",
    "            input_eeg = train_eeg[batch_indices].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                feature_eeg = NET_EEG(input_eeg)\n",
    "            \n",
    "            labels_batch = train_labels[batch_indices].to(device)\n",
    "            output_class = classifier(feature_eeg.detach())\n",
    "            classifier_loss = criterion(output_class, labels_batch)\n",
    "            \n",
    "            classifier_loss.backward()\n",
    "            optimizer_classifier.step()\n",
    "            \n",
    "            # Track losses\n",
    "            fold_costs.append(mfmc_loss.item())\n",
    "            fold_classifier_losses.append(classifier_loss.item())\n",
    "            \n",
    "            # Progress logging\n",
    "            if iteration % 500 == 0:\n",
    "                print(f'Fold {fold_num} - Iter {iteration:5d} | MFMC: {mfmc_loss.item():.6f} | Classifier: {classifier_loss.item():.6f}')\n",
    "            \n",
    "            # Evaluation\n",
    "            if iteration % EVAL_INTERVAL == 0:\n",
    "                NET_EEG.eval()\n",
    "                classifier.eval()\n",
    "                \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                test_batch_size = 100\n",
    "                num_test_batches = (len(test_eeg) + test_batch_size - 1) // test_batch_size\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for batch_idx in range(num_test_batches):\n",
    "                        start_idx = batch_idx * test_batch_size\n",
    "                        end_idx = min((batch_idx + 1) * test_batch_size, len(test_eeg))\n",
    "                        \n",
    "                        test_eeg_batch = test_eeg[start_idx:end_idx].to(device)\n",
    "                        test_labels_batch = test_labels[start_idx:end_idx].to(device)\n",
    "                        \n",
    "                        outputs = classifier(NET_EEG(test_eeg_batch))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        \n",
    "                        total += test_labels_batch.size(0)\n",
    "                        correct += (predicted == test_labels_batch).sum().item()\n",
    "                \n",
    "                fold_accuracy = correct / total\n",
    "                fold_test_accuracies.append(fold_accuracy)\n",
    "                \n",
    "                if fold_accuracy > fold_best_accuracy:\n",
    "                    fold_best_accuracy = fold_accuracy\n",
    "                \n",
    "                NET_EEG.train()\n",
    "                classifier.train()\n",
    "        \n",
    "        # Save fold results\n",
    "        fold_time = time.time() - fold_start_time\n",
    "        fold_results.append({\n",
    "            'fold': fold_num,\n",
    "            'best_accuracy': fold_best_accuracy,\n",
    "            'final_accuracy': fold_test_accuracies[-1] if fold_test_accuracies else 0,\n",
    "            'training_time': fold_time,\n",
    "            'costs': fold_costs,\n",
    "            'classifier_losses': fold_classifier_losses,\n",
    "            'test_accuracies': fold_test_accuracies\n",
    "        })\n",
    "        \n",
    "        # Store fold data for plotting\n",
    "        all_fold_costs.append(fold_costs)\n",
    "        all_fold_classifier_losses.append(fold_classifier_losses)\n",
    "        all_fold_test_accuracies.append(fold_test_accuracies)\n",
    "\n",
    "        \n",
    "        print(f\"Fold {fold_num} completed - Best accuracy: {fold_best_accuracy:.4f}\")\n",
    "    \n",
    "    # Calculate cross-validation statistics\n",
    "    best_accuracies = [result['best_accuracy'] for result in fold_results]\n",
    "    final_accuracies = [result['final_accuracy'] for result in fold_results]\n",
    "    \n",
    "    cv_mean_best = np.mean(best_accuracies)\n",
    "    cv_std_best = np.std(best_accuracies)\n",
    "    cv_mean_final = np.mean(final_accuracies)\n",
    "    cv_std_final = np.std(final_accuracies)\n",
    "    \n",
    "    total_cv_time = time.time() - total_cv_start_time\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Best Accuracy - Mean: {cv_mean_best:.4f} ± {cv_std_best:.4f}\")\n",
    "    print(f\"Final Accuracy - Mean: {cv_mean_final:.4f} ± {cv_std_final:.4f}\")\n",
    "    print(f\"Total CV Time: {str(timedelta(seconds=int(total_cv_time)))}\")\n",
    "    print(\"\\\\nPer-fold results:\")\n",
    "    for result in fold_results:\n",
    "        print(f\"  Fold {result['fold']}: Best={result['best_accuracy']:.4f}, Final={result['final_accuracy']:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot start training - data loading failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_learning_curves(costs, classifier_errors, test_accuracies, save_path, fold=None):\n",
    "    \"\"\"Plot training curves for MFMC demo in 2x2 layout\"\"\"\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot MFMC cost\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(costs)\n",
    "    fold_text = f' (Fold {fold})' if fold is not None else ''\n",
    "    plt.title(f'MFMC Tri-modal Projection Loss{fold_text}')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot classifier error\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(classifier_errors)\n",
    "    plt.title(f'Classifier Cross-Entropy Loss{fold_text}')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot test accuracy\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(test_accuracies)\n",
    "    plt.title(f'Test Accuracy{fold_text}')\n",
    "    plt.xlabel(f'Evaluation (x{EVAL_INTERVAL} iterations)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    # Normalize losses for comparison\n",
    "    norm_mfmc = np.array(costs) / (np.max(costs) if len(costs) > 0 and np.max(costs) > 0 else 1)\n",
    "    norm_classifier = np.array(classifier_errors) / (np.max(classifier_errors) if len(classifier_errors) > 0 and np.max(classifier_errors) > 0 else 1)\n",
    "    \n",
    "    plt.plot(norm_mfmc, label='MFMC Loss (normalized)', alpha=0.7)\n",
    "    plt.plot(norm_classifier, label='Classifier Loss (normalized)', alpha=0.7)\n",
    "    plt.title(f'Loss Comparison{fold_text}')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Normalized Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUATION AND VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def plot_learning_curves(costs, classifier_errors, test_accuracies, save_path, fold=None):\n",
    "    \"\"\"Plot training curves for MFMC demo in 2x2 layout\"\"\"\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot MFMC cost\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(costs)\n",
    "    fold_text = f' (Fold {fold})' if fold is not None else ''\n",
    "    plt.title(f'MFMC Tri-modal Projection Loss{fold_text}')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot classifier error\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(classifier_errors)\n",
    "    plt.title(f'Classifier Cross-Entropy Loss{fold_text}')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot test accuracy\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(test_accuracies)\n",
    "    plt.title(f'Test Accuracy{fold_text}')\n",
    "    plt.xlabel(f'Evaluation (x{EVAL_INTERVAL} iterations)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    # Normalize losses for comparison\n",
    "    norm_mfmc = np.array(costs) / (np.max(costs) if len(costs) > 0 and np.max(costs) > 0 else 1)\n",
    "    norm_classifier = np.array(classifier_errors) / (np.max(classifier_errors) if len(classifier_errors) > 0 and np.max(classifier_errors) > 0 else 1)\n",
    "    \n",
    "    plt.plot(norm_mfmc, label='MFMC Loss (normalized)', alpha=0.7)\n",
    "    plt.plot(norm_classifier, label='Classifier Loss (normalized)', alpha=0.7)\n",
    "    plt.title(f'Loss Comparison{fold_text}')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Normalized Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"Create and display confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "    plt.title('MFMC Confusion Matrix - Emotion Recognition')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if data_loaded and 'fold_results' in locals():\n",
    "    print(\"Generating 5-fold cross-validation summary and visualizations...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create average learning curves across all folds\n",
    "    def plot_cv_summary(all_fold_costs, all_fold_classifier_losses, all_fold_test_accuracies, save_path):\n",
    "        \"\"\"Plot average learning curves across all folds in 2x2 layout\"\"\"\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Calculate average and std across folds\n",
    "        max_len_costs = max(len(costs) for costs in all_fold_costs)\n",
    "        max_len_classifier = max(len(losses) for losses in all_fold_classifier_losses)\n",
    "        max_len_accuracy = max(len(acc) for acc in all_fold_test_accuracies)\n",
    "        \n",
    "        # Pad sequences to same length\n",
    "        padded_costs = []\n",
    "        padded_classifier = []\n",
    "        padded_accuracy = []\n",
    "        \n",
    "        for i in range(len(all_fold_costs)):\n",
    "            costs = all_fold_costs[i] + [all_fold_costs[i][-1]] * (max_len_costs - len(all_fold_costs[i]))\n",
    "            classifier = all_fold_classifier_losses[i] + [all_fold_classifier_losses[i][-1]] * (max_len_classifier - len(all_fold_classifier_losses[i]))\n",
    "            accuracy = all_fold_test_accuracies[i] + [all_fold_test_accuracies[i][-1]] * (max_len_accuracy - len(all_fold_test_accuracies[i]))\n",
    "            \n",
    "            padded_costs.append(costs)\n",
    "            padded_classifier.append(classifier)\n",
    "            padded_accuracy.append(accuracy)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        costs_array = np.array(padded_costs)\n",
    "        classifier_array = np.array(padded_classifier)\n",
    "        accuracy_array = np.array(padded_accuracy)\n",
    "        \n",
    "        # Calculate means and stds\n",
    "        costs_mean = np.mean(costs_array, axis=0)\n",
    "        costs_std = np.std(costs_array, axis=0)\n",
    "        classifier_mean = np.mean(classifier_array, axis=0)\n",
    "        classifier_std = np.std(classifier_array, axis=0)\n",
    "        accuracy_mean = np.mean(accuracy_array, axis=0)\n",
    "        accuracy_std = np.std(accuracy_array, axis=0)\n",
    "        \n",
    "        # Plot MFMC cost with error bars\n",
    "        plt.subplot(2, 2, 1)\n",
    "        x_costs = np.arange(len(costs_mean))\n",
    "        plt.plot(x_costs, costs_mean, 'b-', label='Mean')\n",
    "        plt.fill_between(x_costs, costs_mean - costs_std, costs_mean + costs_std, alpha=0.3)\n",
    "        plt.title('MFMC Loss (5-Fold Average)')\n",
    "        plt.xlabel('Iteration (x100)')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot classifier loss with error bars\n",
    "        plt.subplot(2, 2, 2)\n",
    "        x_classifier = np.arange(len(classifier_mean))\n",
    "        plt.plot(x_classifier, classifier_mean, 'r-', label='Mean')\n",
    "        plt.fill_between(x_classifier, classifier_mean - classifier_std, classifier_mean + classifier_std, alpha=0.3)\n",
    "        plt.title('Classifier Loss (5-Fold Average)')\n",
    "        plt.xlabel('Iteration (x100)')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot test accuracy with error bars\n",
    "        plt.subplot(2, 2, 3)\n",
    "        x_accuracy = np.arange(len(accuracy_mean))\n",
    "        plt.plot(x_accuracy, accuracy_mean, 'g-', label='Mean')\n",
    "        plt.fill_between(x_accuracy, accuracy_mean - accuracy_std, accuracy_mean + accuracy_std, alpha=0.3)\n",
    "        plt.title('Test Accuracy (5-Fold Average)')\n",
    "        plt.xlabel(f'Evaluation (x{EVAL_INTERVAL} iterations)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot final accuracy distribution across folds\n",
    "        plt.subplot(2, 2, 4)\n",
    "        final_accuracies = [result['best_accuracy'] for result in fold_results]\n",
    "        fold_numbers = [result['fold'] for result in fold_results]\n",
    "        \n",
    "        bars = plt.bar(fold_numbers, final_accuracies, alpha=0.7)\n",
    "        plt.axhline(y=np.mean(final_accuracies), color='r', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(final_accuracies):.4f}')\n",
    "        plt.title('Best Accuracy per Fold')\n",
    "        plt.xlabel('Fold')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Color bars based on performance\n",
    "        for i, bar in enumerate(bars):\n",
    "            if final_accuracies[i] >= np.mean(final_accuracies):\n",
    "                bar.set_color('green')\n",
    "            else:\n",
    "                bar.set_color('orange')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # Generate comprehensive summary plot\n",
    "    plot_cv_summary(all_fold_costs, all_fold_classifier_losses, all_fold_test_accuracies,\n",
    "                   f'{RESULTS_DIR}/cv_summary_curves.png')\n",
    "    \n",
    "    # Create detailed summary table\n",
    "    def plot_cv_results_table(fold_results, save_path):\n",
    "        \"\"\"Create a comprehensive results table\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Prepare table data\n",
    "        table_data = [\n",
    "            ['Metric', 'Mean ± Std', 'Min', 'Max'],\n",
    "            ['', '', '', '']  # Empty row\n",
    "        ]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        best_accs = [r['best_accuracy'] for r in fold_results]\n",
    "        final_accs = [r['final_accuracy'] for r in fold_results] \n",
    "        times = [r['training_time'] for r in fold_results]\n",
    "        \n",
    "        metrics = [\n",
    "            ('Best Accuracy', best_accs),\n",
    "            ('Final Accuracy', final_accs),\n",
    "            ('Training Time (min)', [t/60 for t in times])\n",
    "        ]\n",
    "        \n",
    "        for metric_name, values in metrics:\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values)\n",
    "            min_val = np.min(values)\n",
    "            max_val = np.max(values)\n",
    "            \n",
    "            if 'Time' in metric_name:\n",
    "                table_data.append([\n",
    "                    metric_name,\n",
    "                    f\"{mean_val:.1f} ± {std_val:.1f}\",\n",
    "                    f\"{min_val:.1f}\",\n",
    "                    f\"{max_val:.1f}\"\n",
    "                ])\n",
    "            else:\n",
    "                table_data.append([\n",
    "                    metric_name,\n",
    "                    f\"{mean_val:.4f} ± {std_val:.4f}\",\n",
    "                    f\"{min_val:.4f}\",\n",
    "                    f\"{max_val:.4f}\"\n",
    "                ])\n",
    "        \n",
    "        # Add fold-specific results\n",
    "        table_data.append(['', '', '', ''])  # Empty row\n",
    "        table_data.append(['Fold-Specific Results', '', '', ''])\n",
    "        \n",
    "        for result in fold_results:\n",
    "            table_data.append([\n",
    "                f\"Fold {result['fold']}\",\n",
    "                f\"{result['best_accuracy']:.4f}\",\n",
    "                f\"{result['final_accuracy']:.4f}\",\n",
    "                f\"{result['training_time']/60:.1f} min\"\n",
    "            ])\n",
    "        \n",
    "        # Create table\n",
    "        table = ax.table(cellText=table_data, loc='center', cellLoc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(11)\n",
    "        table.scale(1, 2)\n",
    "        \n",
    "        # Style header\n",
    "        for j in range(len(table_data[0])):\n",
    "            table[(0, j)].set_facecolor('#4472C4')\n",
    "            table[(0, j)].set_text_props(color='white', weight='bold')\n",
    "            \n",
    "        # Style section headers\n",
    "        for i, row in enumerate(table_data):\n",
    "            if 'Fold-Specific Results' in row[0]:\n",
    "                for j in range(len(row)):\n",
    "                    table[(i, j)].set_facecolor('#70AD47')\n",
    "                    table[(i, j)].set_text_props(color='white', weight='bold')\n",
    "        \n",
    "        plt.title('5-Fold Cross-Validation Results Summary\\\\nSubject-Dependent MFMC', \n",
    "                 pad=20, fontsize=16, weight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # Generate results table\n",
    "    plot_cv_results_table(fold_results, f'{RESULTS_DIR}/cv_results_table.png')\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    cv_results = {\n",
    "        'cv_statistics': {\n",
    "            'best_accuracy_mean': cv_mean_best,\n",
    "            'best_accuracy_std': cv_std_best,\n",
    "            'final_accuracy_mean': cv_mean_final,\n",
    "            'final_accuracy_std': cv_std_final,\n",
    "            'total_cv_time': total_cv_time\n",
    "        },\n",
    "        'fold_results': fold_results,\n",
    "        'all_fold_data': {\n",
    "            'costs': all_fold_costs,\n",
    "            'classifier_losses': all_fold_classifier_losses,\n",
    "            'test_accuracies': all_fold_test_accuracies\n",
    "        },\n",
    "        'config': {\n",
    "            'n_folds': N_FOLDS,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'total_iterations_per_fold': TOTAL_ITERATIONS,\n",
    "            'cov_beta': COV_BETA,\n",
    "            'learning_rate_encoder': LEARNING_RATE_ENCODER,\n",
    "            'learning_rate_classifier': LEARNING_RATE_CLASSIFIER,\n",
    "            'use_class_balancing': USE_CLASS_BALANCING,\n",
    "            'random_seed': RANDOM_SEED\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    np.save(f'{RESULTS_DIR}/cv_results.npy', cv_results)\n",
    "    print(f\"Comprehensive CV results saved to {RESULTS_DIR}/cv_results.npy\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"SUBJECT-DEPENDENT 5-FOLD CV MFMC DEMO COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"FINAL SUMMARY:\")\n",
    "    print(f\"Cross-validation completed successfully\")\n",
    "    print(f\"Mean best accuracy: {cv_mean_best:.4f} ± {cv_std_best:.4f}\")\n",
    "    print(f\"Mean final accuracy: {cv_mean_final:.4f} ± {cv_std_final:.4f}\")\n",
    "    print(f\"Total training time: {str(timedelta(seconds=int(total_cv_time)))}\")\n",
    "    print(f\"All visualizations and results saved to: {RESULTS_DIR}\")\n",
    "    print(\"\\\\nGenerated files:\")\n",
    "    print(f\"- Individual fold curves: fold_1_curves.png to fold_{N_FOLDS}_curves.png\")\n",
    "    print(f\"- CV summary curves: cv_summary_curves.png\")\n",
    "    print(f\"- Results table: cv_results_table.png\")\n",
    "    print(f\"- Complete results: cv_results.npy\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot perform evaluation - cross-validation was not completed or data not loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
