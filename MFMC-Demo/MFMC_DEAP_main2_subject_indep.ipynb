{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7cdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFMC Demo for DEAP Dataset - Subject-Independent Emotion Recognition\n",
    "# Multi-modal Feature Matching and Correlation (MFMC) approach\n",
    "# Cross-subject evaluation: Training and testing on different subjects\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(\"MFMC Subject-Independent Demo for DEAP Dataset\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73766a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPERIMENT CONFIGURATION - Subject-Independent Setup\n",
    "# =============================================================================\n",
    "\n",
    "# Define base paths\n",
    "BASE_PATH = 'MFMC-Demo'\n",
    "DATA_DIR = f'{BASE_PATH}/Data_processed'\n",
    "RESULTS_DIR = f'{BASE_PATH}/subject_indep_results'\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 200\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "TOTAL_ITERATIONS = 20001  # Reduced for demo purposes (per fold)\n",
    "EVAL_INTERVAL = 500       # Evaluate every 500 iterations\n",
    "\n",
    "# Cross-validation parameters\n",
    "N_FOLDS = 5              # Number of cross-validation folds\n",
    "RANDOM_SEED = 42         # For reproducible results\n",
    "\n",
    "# Optimizer parameters\n",
    "LEARNING_RATE_ENCODER = 0.0003\n",
    "LEARNING_RATE_CLASSIFIER = 0.0003\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "\n",
    "# MFMC parameters\n",
    "COV_BETA = 0.5           # Exponential moving average coefficient for covariance tracking\n",
    "\n",
    "# Data preprocessing parameters\n",
    "USE_CLASS_BALANCING = True         # Class-weighted loss for imbalanced data\n",
    "\n",
    "# Subject split parameters\n",
    "NUM_TRAIN_SUBJECTS = 15    # 15 subjects for training (79%) 4 subjects for testing (21%)\n",
    "\n",
    "print(\"Subject-Independent Configuration loaded!\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"Total iterations: {TOTAL_ITERATIONS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Training subjects: 1-{NUM_TRAIN_SUBJECTS}\")\n",
    "print(f\"Testing subjects: {NUM_TRAIN_SUBJECTS+1}-19\")\n",
    "print(f\"Cross-subject evaluation setup complete!\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ac8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MFMC LOSS FUNCTIONS AND PROJECTION HEAD - Subject-Independent Version\n",
    "# =============================================================================\n",
    "\n",
    "def adaptive_estimation(v_t, beta, square_term, i):\n",
    "    \"\"\"\n",
    "    Adaptive smoothing filter for estimating covariances\n",
    "    \n",
    "    Args:\n",
    "        v_t: Previous covariance estimate\n",
    "        beta: Exponential moving average coefficient\n",
    "        square_term: Current covariance matrix\n",
    "        i: Current iteration number\n",
    "    \n",
    "    Returns:\n",
    "        Updated covariance estimate and bias-corrected estimate\n",
    "    \"\"\"\n",
    "    v_t = beta * v_t + (1 - beta) * square_term.detach()\n",
    "    return v_t, (v_t / (1 - beta ** i))\n",
    "\n",
    "def MFMC_t_trace(x, y, track_cov, i, cov_beta=0.95):\n",
    "    \"\"\"\n",
    "    Compute MFMC-T trace loss for a single pair of feature matrices\n",
    "    \n",
    "    This function implements the core MFMC trace loss that maximizes\n",
    "    the correlation between features from different modalities for\n",
    "    subject-independent learning.\n",
    "    \n",
    "    Args:\n",
    "        x: Feature matrix from first modality [batch_size, feature_dim]\n",
    "        y: Feature matrix from second modality [batch_size, feature_dim]\n",
    "        track_cov: Dictionary containing tracking variables for covariances\n",
    "        i: Current iteration number\n",
    "        cov_beta: Exponential moving average coefficient for covariance tracking\n",
    "    \n",
    "    Returns:\n",
    "        track_cov: Updated tracking dictionary\n",
    "        loss: MFMC-T trace loss value\n",
    "    \"\"\"\n",
    "    # Calculate auto-covariances and cross-covariance\n",
    "    Rx = (x.T @ x) / x.shape[0]\n",
    "    Ry = (y.T @ y) / y.shape[0]\n",
    "    Pxy = (x.T @ y) / x.shape[0]\n",
    "    \n",
    "    # Add small epsilon for numerical stability\n",
    "    eps = 1e-6\n",
    "    Rx = Rx + torch.eye(Rx.shape[0]).to(Rx.device) * eps\n",
    "    Ry = Ry + torch.eye(Ry.shape[0]).to(Ry.device) * eps\n",
    "    \n",
    "    # Update tracking estimates using adaptive estimation\n",
    "    track_cov['Rx'], Rx_est = adaptive_estimation(track_cov['Rx'], cov_beta, Rx, i)\n",
    "    track_cov['Ry'], Ry_est = adaptive_estimation(track_cov['Ry'], cov_beta, Ry, i)\n",
    "    track_cov['Pxy'], Pxy_est = adaptive_estimation(track_cov['Pxy'], cov_beta, Pxy, i)\n",
    "    \n",
    "    # Compute matrix inverses\n",
    "    Rx_est_inv = torch.inverse(Rx_est)\n",
    "    Ry_est_inv = torch.inverse(Ry_est)\n",
    "    \n",
    "    # Compute MFMC-T trace cost (maximizes cross-modal correlation)\n",
    "    cost = -Rx_est_inv @ Rx @ Rx_est_inv @ Pxy_est @ Ry_est_inv @ Pxy_est.T \\\n",
    "           + Rx_est_inv @ Pxy @ Ry_est_inv @ Pxy_est.T \\\n",
    "           - Rx_est_inv @ Pxy_est @ Ry_est_inv @ Ry @ Ry_est_inv @ Pxy_est.T \\\n",
    "           + Rx_est_inv @ Pxy_est @ Ry_est_inv @ Pxy.T\n",
    "    \n",
    "    # Return negative trace as the loss (to minimize)\n",
    "    loss = -torch.trace(cost)\n",
    "    \n",
    "    return track_cov, loss\n",
    "\n",
    "def tri_modal_projection_loss(fe1, fe2, fe3, proj12, proj23, proj13, trackers, step, cov_beta=0.5):\n",
    "    \"\"\"\n",
    "    Compute the tri-modal projection loss for subject-independent MFMC\n",
    "    \n",
    "    The loss function is: L = MFMC(E1, P23(E2⊕E3)) + MFMC(E2, P13(E1⊕E3)) + MFMC(E3, P12(E1⊕E2))\n",
    "    \n",
    "    This creates three pairwise correlations that help learn subject-invariant features:\n",
    "    - EEG features with projected EOG+TEMP features\n",
    "    - EOG features with projected EEG+TEMP features  \n",
    "    - TEMP features with projected EEG+EOG features\n",
    "    \n",
    "    Args:\n",
    "        fe1: EEG features [batch_size, 128]\n",
    "        fe2: EOG features [batch_size, 128]\n",
    "        fe3: TEMP features [batch_size, 128]\n",
    "        proj12: Projection head for E1⊕E2 → 128D\n",
    "        proj23: Projection head for E2⊕E3 → 128D\n",
    "        proj13: Projection head for E1⊕E3 → 128D\n",
    "        trackers: Dictionary containing three covariance trackers\n",
    "        step: Current iteration number\n",
    "        cov_beta: Exponential moving average coefficient for covariance tracking\n",
    "    \n",
    "    Returns:\n",
    "        trackers: Updated covariance trackers\n",
    "        total_loss: Sum of three MFMC-T losses\n",
    "    \"\"\"\n",
    "    # Concatenate features for projection (256D input for each projection head)\n",
    "    concat_12 = torch.cat([fe1, fe2], dim=1)  # EEG + EOG → [batch_size, 256]\n",
    "    concat_23 = torch.cat([fe2, fe3], dim=1)  # EOG + TEMP → [batch_size, 256]\n",
    "    concat_13 = torch.cat([fe1, fe3], dim=1)  # EEG + TEMP → [batch_size, 256]\n",
    "    \n",
    "    # Apply projection heads to get 128D representations\n",
    "    proj_12 = proj12(concat_12)  # [batch_size, 128]\n",
    "    proj_23 = proj23(concat_23)  # [batch_size, 128]\n",
    "    proj_13 = proj13(concat_13)  # [batch_size, 128]\n",
    "    \n",
    "    # Compute MFMC losses for each modality pairing\n",
    "    # Loss 1: MFMC(EEG, P23(EOG⊕TEMP))\n",
    "    trackers['track_1_23'], loss1 = MFMC_t_trace(fe1, proj_23, trackers['track_1_23'], step, cov_beta)\n",
    "    \n",
    "    # Loss 2: MFMC(EOG, P13(EEG⊕TEMP))\n",
    "    trackers['track_2_13'], loss2 = MFMC_t_trace(fe2, proj_13, trackers['track_2_13'], step, cov_beta)\n",
    "    \n",
    "    # Loss 3: MFMC(TEMP, P12(EEG⊕EOG))\n",
    "    trackers['track_3_12'], loss3 = MFMC_t_trace(fe3, proj_12, trackers['track_3_12'], step, cov_beta)\n",
    "    \n",
    "    # Total tri-modal loss\n",
    "    total_loss = loss1 + loss2 + loss3\n",
    "    \n",
    "    return trackers, total_loss\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    2-layer MLP projection head for subject-independent MFMC\n",
    "    \n",
    "    Architecture: Linear(256→512) + BN + ReLU → Linear(512→128) + BN\n",
    "    \n",
    "    Takes concatenated features from two modalities (256D) and projects\n",
    "    to a common 128D representation space for correlation computation.\n",
    "    Designed to learn subject-invariant projections.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=256, hidden_dim=512, output_dim=128):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "print(\"MFMC loss functions for subject-independent learning defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36729448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NEURAL NETWORK ARCHITECTURES - Subject-Independent Design\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "class NETWORK_F_MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer perceptron for feature transformation\n",
    "    Designed to learn subject-invariant representations\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=784, hidden_dim=200, out_dim=200, num_layers=2):\n",
    "        super(NETWORK_F_MLP, self).__init__()\n",
    "        self.dim = out_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.fc_list = []\n",
    "        self.bn_list = []\n",
    "        \n",
    "        # First layer\n",
    "        self.fc_list.append(nn.Linear(input_dim, hidden_dim, bias=True))\n",
    "        self.bn_list.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(self.num_layers - 1):\n",
    "            self.fc_list.append(nn.Linear(hidden_dim, hidden_dim, bias=True))\n",
    "            self.bn_list.append(nn.BatchNorm1d(hidden_dim))\n",
    "            \n",
    "        self.fc_list = nn.ModuleList(self.fc_list)\n",
    "        self.bn_list = nn.ModuleList(self.bn_list)\n",
    "\n",
    "        # Final layer\n",
    "        self.fc_final = nn.Linear(hidden_dim, out_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.fc_list[i](x)\n",
    "            x = torch.relu(x)\n",
    "            x = self.bn_list[i](x)\n",
    "        \n",
    "        x = self.fc_final(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class Advanced1DCNN_channel(nn.Module):\n",
    "    \"\"\"\n",
    "    Advanced 1D CNN for processing physiological signals\n",
    "    \n",
    "    This network processes multi-channel time series data (EEG, EOG, Temperature)\n",
    "    with emphasis on learning subject-invariant features through deep convolution\n",
    "    and batch normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channel=1, num_classes=128, input_size=1280):\n",
    "        super(Advanced1DCNN_channel, self).__init__()\n",
    "        \n",
    "        # Convolutional layers with increasing depth\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=11, padding=5),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=11, padding=5),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=11, padding=5),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=11, padding=5),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        )\n",
    "\n",
    "        # Calculate the size after all convolutional layers\n",
    "        feat_size = input_size // (4 * 4 * 4 * 4)  # 4 max-pooling layers with stride 4\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256 * feat_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Multi-layer perceptron for final feature processing\n",
    "        self.MLP = NETWORK_F_MLP(\n",
    "            input_dim=128 * input_channel, \n",
    "            hidden_dim=4000, \n",
    "            out_dim=num_classes, \n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, channels = x.shape[0], x.shape[1]\n",
    "        \n",
    "        # Process each channel separately through CNN\n",
    "        x = x.unsqueeze(2)  # Add temporal dimension\n",
    "        x = x.flatten(0, 1)  # Combine batch and channel dimensions\n",
    "        \n",
    "        # Convolutional feature extraction\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        \n",
    "        # Flatten and process through FC layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        # Reshape and process through MLP\n",
    "        out = out.reshape(batch_size, channels, -1)\n",
    "        out = out.flatten(-2, -1)\n",
    "        out = self.MLP(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ComplexClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer classifier for subject-independent emotion recognition\n",
    "    \n",
    "    Takes 128D features from any modality and predicts emotion class.\n",
    "    Designed with batch normalization to handle subject variability.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_features=128, num_classes=4):\n",
    "        super(ComplexClassifier, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(dim_features, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.fc4(x)  # No activation - CrossEntropyLoss includes softmax\n",
    "        return x\n",
    "\n",
    "print(\"Neural network architectures for subject-independent learning defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING AND SUBJECT-INDEPENDENT SPLITTING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Loading DEAP dataset for subject-independent evaluation...\")\n",
    "print(\"Key difference: Training and testing on completely different subjects\")\n",
    "print(\"- Training: Subject 1-15 (never seen during testing)\")\n",
    "print(\"- Testing: Subject 16-19 (never seen during training)\")\n",
    "\n",
    "try:\n",
    "    # Load preprocessed DEAP data\n",
    "    print(f\"Loading data from: {DATA_DIR}\")\n",
    "    \n",
    "    subject = np.load(f'{DATA_DIR}/subject.npy')\n",
    "    emotion_labels = np.load(f'{DATA_DIR}/emotion_labels.npy')\n",
    "    eeg_data = np.load(f'{DATA_DIR}/eeg_data.npy')\n",
    "    eog_data = np.load(f'{DATA_DIR}/eog_data.npy')\n",
    "    temp_data = np.load(f'{DATA_DIR}/temp_data.npy')\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    subject = torch.from_numpy(subject).long()\n",
    "    emotion_labels = torch.from_numpy(emotion_labels).long()\n",
    "    eeg_data = torch.from_numpy(eeg_data).float()\n",
    "    eog_data = torch.from_numpy(eog_data).float()\n",
    "    temp_data = torch.from_numpy(temp_data).float()\n",
    "    \n",
    "    print(\"\\\\nData loaded successfully!\")\n",
    "    print(f\"Dataset statistics:\")\n",
    "    print(f\"- Total samples: {eeg_data.shape[0]}\")\n",
    "    print(f\"- EEG shape: {eeg_data.shape} (samples, channels, time_points)\")\n",
    "    print(f\"- EOG shape: {eog_data.shape}\")\n",
    "    print(f\"- Temperature shape: {temp_data.shape}\")\n",
    "    print(f\"- Emotion labels shape: {emotion_labels.shape}\")\n",
    "    print(f\"- Number of unique subjects: {len(torch.unique(subject))}\")\n",
    "    print(f\"- Number of emotion classes: {len(torch.unique(emotion_labels))}\")\n",
    "    \n",
    "    # CRITICAL: Subject-Independent 5-Fold Cross-Validation\n",
    "    # This creates 5 folds where each fold has completely different subjects for train/test\n",
    "    available_subjects = np.unique(subject).tolist()\n",
    "    print(f\"\\\\nSubject-Independent 5-Fold CV Configuration:\")\n",
    "    print(f\"Available subjects: {available_subjects}\")\n",
    "    print(f\"Total available subjects: {len(available_subjects)}\")\n",
    "    \n",
    "    # Manually specified subject splits for each fold\n",
    "    print(\"\\\\nUsing manually specified subject splits:\")\n",
    "    \n",
    "    # Define manual fold splits - each fold has specific train/test subjects\n",
    "    manual_fold_splits = [\n",
    "        {\n",
    "            'fold': 1,\n",
    "            'train_subjects': [5, 18, 20, 6, 14, 19, 12, 1, 13, 2, 22, 7, 9, 0, 3],\n",
    "            'test_subjects': [17, 15, 4, 11]\n",
    "        },\n",
    "        {\n",
    "            'fold': 2,\n",
    "            'train_subjects': [17, 15, 4, 11, 14, 19, 12, 1, 13, 2, 22, 7, 9, 0, 3],\n",
    "            'test_subjects': [5, 18, 20, 6]\n",
    "        },\n",
    "        {\n",
    "            'fold': 3,\n",
    "            'train_subjects': [17, 15, 4, 11, 5, 18, 20, 6, 13, 2, 22, 7, 9, 0, 3],\n",
    "            'test_subjects': [14, 19, 12, 1]\n",
    "        },\n",
    "        {\n",
    "            'fold': 4,\n",
    "            'train_subjects': [17, 15, 4, 11, 5, 18, 20, 6, 14, 19, 12, 1, 9, 0, 3],\n",
    "            'test_subjects': [13, 2, 22, 7]\n",
    "        },\n",
    "        {\n",
    "            'fold': 5,\n",
    "            'train_subjects': [17, 15, 4, 11, 18, 20, 6, 14, 19, 12, 1, 13, 2, 22, 7],\n",
    "            'test_subjects': [9, 0, 3, 5]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    fold_splits = []\n",
    "    \n",
    "    for fold_info in manual_fold_splits:\n",
    "        fold_idx = fold_info['fold'] - 1  # Convert to 0-based indexing\n",
    "        fold_train_subjects = fold_info['train_subjects']\n",
    "        fold_test_subjects = fold_info['test_subjects']\n",
    "        \n",
    "        # Get data indices for these subjects\n",
    "        train_data_indices = []\n",
    "        test_data_indices = []\n",
    "        \n",
    "        for subj_id in fold_train_subjects:\n",
    "            train_data_indices.extend(np.where(subject == subj_id)[0])\n",
    "        \n",
    "        for subj_id in fold_test_subjects:\n",
    "            test_data_indices.extend(np.where(subject == subj_id)[0])\n",
    "        \n",
    "        train_data_indices = np.array(train_data_indices)\n",
    "        test_data_indices = np.array(test_data_indices)\n",
    "        \n",
    "        fold_splits.append({\n",
    "            'fold': fold_idx + 1,\n",
    "            'train_subjects': fold_train_subjects,\n",
    "            'test_subjects': fold_test_subjects,\n",
    "            'train_indices': train_data_indices,\n",
    "            'test_indices': test_data_indices,\n",
    "            'train_size': len(train_data_indices),\n",
    "            'test_size': len(test_data_indices)\n",
    "        })\n",
    "        \n",
    "        # Verify no subject overlap\n",
    "        # assert len(set(fold_train_subjects) & set(fold_test_subjects)) == 0, f\"Subject overlap in fold {fold_idx + 1}\"\n",
    "    \n",
    "    print(f\"\\\\nSubject-independent 5-fold cross-validation setup complete!\")\n",
    "    print(f\"Each fold will be trained for {TOTAL_ITERATIONS} iterations\")\n",
    "    print(\"All folds ensure complete subject separation between train/test\")\n",
    "    \n",
    "    data_loaded = True\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please ensure the DEAP dataset is preprocessed and available at the specified path.\")\n",
    "    data_loaded = False\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "    data_loaded = False\n",
    "\n",
    "if data_loaded:\n",
    "    print(\"\\\\nSubject-independent data loading and preprocessing complete!\")\n",
    "    print(\"Ready for cross-subject generalization testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL INITIALIZATION FOR SUBJECT-INDEPENDENT LEARNING\n",
    "# =============================================================================\n",
    "\n",
    "if data_loaded:\n",
    "    print(\"Initializing MFMC models for subject-independent learning...\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize feature extraction networks for each modality\n",
    "    print(\"\\\\nInitializing feature extraction networks:\")\n",
    "    \n",
    "    # EEG feature extractor\n",
    "    NET_EEG = Advanced1DCNN_channel(\n",
    "        input_channel=eeg_data.shape[1], \n",
    "        num_classes=128, \n",
    "        input_size=eeg_data.shape[2]\n",
    "    ).to(device)\n",
    "    print(f\"- EEG Network: {eeg_data.shape[1]} channels → 128D features\")\n",
    "    \n",
    "    # EOG feature extractor\n",
    "    NET_EOG = Advanced1DCNN_channel(\n",
    "        input_channel=eog_data.shape[1], \n",
    "        num_classes=128, \n",
    "        input_size=eog_data.shape[2]\n",
    "    ).to(device)\n",
    "    print(f\"- EOG Network: {eog_data.shape[1]} channels → 128D features\")\n",
    "    \n",
    "    # Temperature feature extractor\n",
    "    NET_TEMP = Advanced1DCNN_channel(\n",
    "        input_channel=temp_data.shape[1], \n",
    "        num_classes=128, \n",
    "        input_size=temp_data.shape[2]\n",
    "    ).to(device)\n",
    "    print(f\"- Temperature Network: {temp_data.shape[1]} channels → 128D features\")\n",
    "    \n",
    "    # Initialize projection heads for MFMC tri-modal loss\n",
    "    print(\"\\\\nInitializing MFMC projection heads for subject-invariant learning:\")\n",
    "    proj_12 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)  # EEG + EOG\n",
    "    proj_23 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)  # EOG + TEMP\n",
    "    proj_13 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)  # EEG + TEMP\n",
    "    print(\"Projection heads initialized for subject-invariant tri-modal loss\")\n",
    "    \n",
    "    # Initialize emotion classifier\n",
    "    num_classes = len(torch.unique(emotion_labels))\n",
    "    classifier = ComplexClassifier(dim_features=128, num_classes=num_classes).to(device)\n",
    "    print(f\"\\\\nEmotion classifier: 128D features → {num_classes} emotion classes\")\n",
    "    \n",
    "    # Initialize loss function based on class balancing setting\n",
    "    # Note: Class weights will be computed separately for each fold during training\n",
    "    if USE_CLASS_BALANCING:\n",
    "        print(\"Class balancing ENABLED - weights will be computed for each fold\")\n",
    "    else:\n",
    "        print(\"Class balancing DISABLED\")\n",
    "        \n",
    "    # Initialize with standard loss (will be updated per fold if needed)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Setup optimizers - include projection heads in the feature extractor optimizer\n",
    "    print(\"\\\\nSetting up optimizers for subject-independent training:\")\n",
    "    \n",
    "    # Feature extractor optimizer (includes all encoders and projection heads)\n",
    "    all_feature_params = (list(NET_EEG.parameters()) + list(NET_EOG.parameters()) + \n",
    "                         list(NET_TEMP.parameters()) + list(proj_12.parameters()) + \n",
    "                         list(proj_23.parameters()) + list(proj_13.parameters()))\n",
    "    \n",
    "    optimizer_features = optim.Adam(\n",
    "        all_feature_params, \n",
    "        lr=LEARNING_RATE_ENCODER, \n",
    "        betas=(BETA1, BETA2), \n",
    "        amsgrad=True\n",
    "    )\n",
    "    print(f\"- Feature extractor optimizer: Adam (lr={LEARNING_RATE_ENCODER})\")\n",
    "    \n",
    "    # Classifier optimizer\n",
    "    optimizer_classifier = optim.Adam(\n",
    "        classifier.parameters(), \n",
    "        lr=LEARNING_RATE_CLASSIFIER, \n",
    "        betas=(BETA1, BETA2), \n",
    "        amsgrad=True\n",
    "    )\n",
    "    print(f\"- Classifier optimizer: Adam (lr={LEARNING_RATE_CLASSIFIER})\")\n",
    "    \n",
    "    # Initialize covariance tracking for MFMC tri-modal loss\n",
    "    print(\"\\\\nInitializing MFMC covariance trackers:\")\n",
    "    feature_dim = 128\n",
    "    trackers = {\n",
    "        'track_1_23': {  # EEG vs EOG+TEMP projection\n",
    "            'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Pxy': torch.zeros(feature_dim, feature_dim).to(device)\n",
    "        },\n",
    "        'track_2_13': {  # EOG vs EEG+TEMP projection\n",
    "            'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Pxy': torch.zeros(feature_dim, feature_dim).to(device)\n",
    "        },\n",
    "        'track_3_12': {  # TEMP vs EEG+EOG projection\n",
    "            'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "            'Pxy': torch.zeros(feature_dim, feature_dim).to(device)\n",
    "        }\n",
    "    }\n",
    "    print(\"Covariance trackers initialized for subject-invariant tri-modal loss\")\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    costs = []\n",
    "    classifier_losses = []\n",
    "    test_accuracies = []\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    print(f\"\\\\nModel initialization complete!\")\n",
    "    print(f\"Ready for subject-independent MFMC training:\")\n",
    "    print(f\"- Phase 1: UNSUPERVISED encoder training (MFMC loss only)\")\n",
    "    print(f\"- Phase 2: SUPERVISED classifier training (CrossEntropy loss)\")\n",
    "    print(f\"- Goal: Learn subject-invariant emotion recognition\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot initialize models - data loading failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0221fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5-FOLD SUBJECT-INDEPENDENT CROSS-VALIDATION TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "if data_loaded:\n",
    "    print(\"Starting 5-fold subject-independent cross-validation...\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TRAINING STRATEGY (Subject-Independent CV):\")\n",
    "    print(\"Phase 1: UNSUPERVISED encoder training with MFMC tri-modal loss\")\n",
    "    print(\"Phase 2: SUPERVISED classifier training with CrossEntropy loss\")\n",
    "    print(\"Goal: Learn subject-invariant features across completely different subjects\")\n",
    "    print(f\"Cross-validation: {N_FOLDS} folds, {TOTAL_ITERATIONS} iterations per fold\")\n",
    "    print(\"Each fold uses completely different subjects for train/test\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Store results across all folds\n",
    "    fold_results = []\n",
    "    all_fold_costs = []\n",
    "    all_fold_classifier_losses = []\n",
    "    all_fold_test_accuracies = []\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    total_cv_start_time = time.time()\n",
    "    \n",
    "    # Start cross-validation\n",
    "    for fold_idx, fold_info in enumerate(fold_splits):\n",
    "        fold_num = fold_info['fold']\n",
    "        train_indices = fold_info['train_indices']\n",
    "        test_indices = fold_info['test_indices']\n",
    "        train_subjects = fold_info['train_subjects']\n",
    "        test_subjects = fold_info['test_subjects']\n",
    "\n",
    "        \n",
    "        # Create fold-specific train/test splits\n",
    "        train_eeg = eeg_data[train_indices]\n",
    "        test_eeg = eeg_data[test_indices]\n",
    "        train_eog = eog_data[train_indices]\n",
    "        test_eog = eog_data[test_indices]\n",
    "        train_temp = temp_data[train_indices]\n",
    "        test_temp = temp_data[test_indices]\n",
    "        train_labels = emotion_labels[train_indices]\n",
    "        test_labels = emotion_labels[test_indices]\n",
    "        \n",
    "        # Check for class balance and compute weights\n",
    "        train_class_counts = torch.bincount(train_labels)\n",
    "        print(f\"Fold {fold_num} class distribution: {train_class_counts.tolist()}\")\n",
    "        \n",
    "        if USE_CLASS_BALANCING:\n",
    "            class_weights = 1.0 / train_class_counts.float()\n",
    "            class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
    "            criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Initialize models for this fold\n",
    "        NET_EEG = Advanced1DCNN_channel(\n",
    "            input_channel=eeg_data.shape[1], num_classes=128, input_size=eeg_data.shape[2]\n",
    "        ).to(device)\n",
    "        NET_EOG = Advanced1DCNN_channel(\n",
    "            input_channel=eog_data.shape[1], num_classes=128, input_size=eog_data.shape[2]\n",
    "        ).to(device)\n",
    "        NET_TEMP = Advanced1DCNN_channel(\n",
    "            input_channel=temp_data.shape[1], num_classes=128, input_size=temp_data.shape[2]\n",
    "        ).to(device)\n",
    "        \n",
    "        proj_12 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)\n",
    "        proj_23 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)\n",
    "        proj_13 = ProjectionHead(input_dim=256, hidden_dim=512, output_dim=128).to(device)\n",
    "        \n",
    "        num_classes = len(torch.unique(emotion_labels))\n",
    "        classifier = ComplexClassifier(dim_features=128, num_classes=num_classes).to(device)\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        all_feature_params = (list(NET_EEG.parameters()) + list(NET_EOG.parameters()) + \n",
    "                             list(NET_TEMP.parameters()) + list(proj_12.parameters()) + \n",
    "                             list(proj_23.parameters()) + list(proj_13.parameters()))\n",
    "        \n",
    "        optimizer_features = optim.Adam(all_feature_params, lr=LEARNING_RATE_ENCODER, \n",
    "                                       betas=(BETA1, BETA2), amsgrad=True)\n",
    "        optimizer_classifier = optim.Adam(classifier.parameters(), lr=LEARNING_RATE_CLASSIFIER, \n",
    "                                         betas=(BETA1, BETA2), amsgrad=True)\n",
    "        \n",
    "        # Initialize covariance trackers\n",
    "        feature_dim = 128\n",
    "        trackers = {\n",
    "            'track_1_23': {'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Pxy': torch.zeros(feature_dim, feature_dim).to(device)},\n",
    "            'track_2_13': {'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Pxy': torch.zeros(feature_dim, feature_dim).to(device)},\n",
    "            'track_3_12': {'Rx': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Ry': torch.zeros(feature_dim, feature_dim).to(device),\n",
    "                          'Pxy': torch.zeros(feature_dim, feature_dim).to(device)}\n",
    "        }\n",
    "        \n",
    "        # Initialize tracking for this fold\n",
    "        fold_costs = []\n",
    "        fold_classifier_losses = []\n",
    "        fold_test_accuracies = []\n",
    "        fold_best_accuracy = 0.0\n",
    "        \n",
    "        fold_start_time = time.time()\n",
    "        \n",
    "        # Training loop for this fold\n",
    "        for iteration in range(1, TOTAL_ITERATIONS):\n",
    "            # Initialize accumulated gradients\n",
    "            total_mfmc_loss = 0\n",
    "            total_classifier_loss = 0\n",
    "            \n",
    "            # =====================================================================\n",
    "            # PHASE 1: UNSUPERVISED ENCODER TRAINING (MFMC Loss Only)\n",
    "            # =====================================================================\n",
    "            optimizer_features.zero_grad()\n",
    "            \n",
    "            # Gradient accumulation loop for encoder training\n",
    "            for acc_step in range(GRADIENT_ACCUMULATION_STEPS):\n",
    "                batch_indices = torch.randint(0, len(train_eeg), (BATCH_SIZE,))\n",
    "                \n",
    "                input_eeg = train_eeg[batch_indices].to(device)\n",
    "                input_eog = train_eog[batch_indices].to(device)\n",
    "                input_temp = train_temp[batch_indices].to(device)\n",
    "                \n",
    "                feature_eeg = NET_EEG(input_eeg)\n",
    "                feature_eog = NET_EOG(input_eog)\n",
    "                feature_temp = NET_TEMP(input_temp)\n",
    "                \n",
    "                trackers, mfmc_loss = tri_modal_projection_loss(\n",
    "                    feature_eeg, feature_eog, feature_temp,\n",
    "                    proj_12, proj_23, proj_13, trackers, iteration, COV_BETA\n",
    "                )\n",
    "                \n",
    "                scaled_mfmc_loss = mfmc_loss / GRADIENT_ACCUMULATION_STEPS\n",
    "                scaled_mfmc_loss.backward()\n",
    "                \n",
    "                total_mfmc_loss += mfmc_loss.item() / GRADIENT_ACCUMULATION_STEPS\n",
    "            \n",
    "            optimizer_features.step()\n",
    "            \n",
    "            # =====================================================================\n",
    "            # PHASE 2: SUPERVISED CLASSIFIER TRAINING (CrossEntropy Loss Only)\n",
    "            # =====================================================================\n",
    "            optimizer_classifier.zero_grad()\n",
    "            \n",
    "            for acc_step in range(GRADIENT_ACCUMULATION_STEPS):\n",
    "                batch_indices = torch.randint(0, len(train_eeg), (BATCH_SIZE,))\n",
    "                input_eeg = train_eeg[batch_indices].to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    feature_eeg = NET_EEG(input_eeg)\n",
    "                \n",
    "                labels_batch = train_labels[batch_indices].to(device)\n",
    "                output_class = classifier(feature_eeg.detach())\n",
    "                classifier_loss = criterion(output_class, labels_batch)\n",
    "                \n",
    "                scaled_classifier_loss = classifier_loss / GRADIENT_ACCUMULATION_STEPS\n",
    "                scaled_classifier_loss.backward()\n",
    "                \n",
    "                total_classifier_loss += classifier_loss.item() / GRADIENT_ACCUMULATION_STEPS\n",
    "            \n",
    "            optimizer_classifier.step()\n",
    "            \n",
    "            # Track losses\n",
    "            fold_costs.append(total_mfmc_loss)\n",
    "            fold_classifier_losses.append(total_classifier_loss)\n",
    "            \n",
    "            # Progress logging\n",
    "            if iteration % 500 == 0:\n",
    "                print(f'Fold {fold_num} - Iter {iteration:5d} | MFMC: {total_mfmc_loss:.6f} | Classifier: {total_classifier_loss:.6f}')\n",
    "            \n",
    "            # Evaluation (cross-subject)\n",
    "            if iteration % EVAL_INTERVAL == 0:\n",
    "                NET_EEG.eval()\n",
    "                classifier.eval()\n",
    "                \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                test_batch_size = 100\n",
    "                num_test_batches = (len(test_eeg) + test_batch_size - 1) // test_batch_size\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for batch_idx in range(num_test_batches):\n",
    "                        start_idx = batch_idx * test_batch_size\n",
    "                        end_idx = min((batch_idx + 1) * test_batch_size, len(test_eeg))\n",
    "                        \n",
    "                        test_eeg_batch = test_eeg[start_idx:end_idx].to(device)\n",
    "                        test_labels_batch = test_labels[start_idx:end_idx].to(device)\n",
    "                        \n",
    "                        outputs = classifier(NET_EEG(test_eeg_batch))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        \n",
    "                        total += test_labels_batch.size(0)\n",
    "                        correct += (predicted == test_labels_batch).sum().item()\n",
    "                \n",
    "                cross_subject_accuracy = correct / total\n",
    "                fold_test_accuracies.append(cross_subject_accuracy)\n",
    "                \n",
    "                if cross_subject_accuracy > fold_best_accuracy:\n",
    "                    fold_best_accuracy = cross_subject_accuracy\n",
    "                \n",
    "                NET_EEG.train()\n",
    "                classifier.train()\n",
    "        \n",
    "        # Save fold results\n",
    "        fold_time = time.time() - fold_start_time\n",
    "        fold_results.append({\n",
    "            'fold': fold_num,\n",
    "            'train_subjects': train_subjects,\n",
    "            'test_subjects': test_subjects,\n",
    "            'best_accuracy': fold_best_accuracy,\n",
    "            'final_accuracy': fold_test_accuracies[-1] if fold_test_accuracies else 0,\n",
    "            'training_time': fold_time,\n",
    "            'costs': fold_costs,\n",
    "            'classifier_losses': fold_classifier_losses,\n",
    "            'test_accuracies': fold_test_accuracies\n",
    "        })\n",
    "        \n",
    "        # Store fold data for plotting\n",
    "        all_fold_costs.append(fold_costs)\n",
    "        all_fold_classifier_losses.append(fold_classifier_losses)\n",
    "        all_fold_test_accuracies.append(fold_test_accuracies)\n",
    "        \n",
    "        \n",
    "        print(f\"Fold {fold_num} completed - Best cross-subject accuracy: {fold_best_accuracy:.4f}\")\n",
    "    \n",
    "    # Calculate cross-validation statistics\n",
    "    best_accuracies = [result['best_accuracy'] for result in fold_results]\n",
    "    final_accuracies = [result['final_accuracy'] for result in fold_results]\n",
    "    \n",
    "    cv_mean_best = np.mean(best_accuracies)\n",
    "    cv_std_best = np.std(best_accuracies)\n",
    "    cv_mean_final = np.mean(final_accuracies)\n",
    "    cv_std_final = np.std(final_accuracies)\n",
    "    \n",
    "    total_cv_time = time.time() - total_cv_start_time\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"5-FOLD SUBJECT-INDEPENDENT CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Cross-Subject Best Accuracy - Mean: {cv_mean_best:.4f} ± {cv_std_best:.4f}\")\n",
    "    print(f\"Cross-Subject Final Accuracy - Mean: {cv_mean_final:.4f} ± {cv_std_final:.4f}\")\n",
    "    print(f\"Total CV Time: {str(timedelta(seconds=int(total_cv_time)))}\")\n",
    "    print(\"\\\\nPer-fold cross-subject results:\")\n",
    "    for result in fold_results:\n",
    "        print(f\"  Fold {result['fold']}: Best={result['best_accuracy']:.4f}, Final={result['final_accuracy']:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot start training - data loading failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUBJECT-INDEPENDENT EVALUATION AND VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def plot_learning_curves(costs, classifier_errors, test_accuracies, save_path, fold=None):\n",
    "    \"\"\"Plot training curves for subject-independent MFMC demo in 2x2 layout\"\"\"\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot MFMC cost\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(costs)\n",
    "    fold_text = f' (Fold {fold})' if fold is not None else ''\n",
    "    plt.title(f'MFMC Tri-modal Projection Loss{fold_text}\\\\n(Subject-Independent)')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot classifier error\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(classifier_errors)\n",
    "    plt.title(f'Classifier Cross-Entropy Loss{fold_text}\\\\n(Subject-Independent)')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot test accuracy\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(test_accuracies)\n",
    "    plt.title(f'Cross-Subject Test Accuracy{fold_text}\\\\n(Unseen Subjects)')\n",
    "    plt.xlabel(f'Evaluation (x{EVAL_INTERVAL} iterations)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    # Normalize losses for comparison\n",
    "    norm_mfmc = np.array(costs) / (np.max(costs) if len(costs) > 0 and np.max(costs) > 0 else 1)\n",
    "    norm_classifier = np.array(classifier_errors) / (np.max(classifier_errors) if len(classifier_errors) > 0 and np.max(classifier_errors) > 0 else 1)\n",
    "    \n",
    "    plt.plot(norm_mfmc, label='MFMC Loss (normalized)', alpha=0.7)\n",
    "    plt.plot(norm_classifier, label='Classifier Loss (normalized)', alpha=0.7)\n",
    "    plt.title(f'Loss Comparison{fold_text}\\\\n(Subject-Independent)')\n",
    "    plt.xlabel('Iteration (x100)')\n",
    "    plt.ylabel('Normalized Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"Create and display confusion matrix for subject-independent results\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "    plt.title('MFMC Confusion Matrix - Subject-Independent Emotion Recognition\\\\n(Tested on Unseen Subjects)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_performance_table(overall_accuracy, class_correct, class_total, all_labels, all_predicted, save_path, quadrant_names):\n",
    "    \"\"\"Create and save performance table for subject-independent results\"\"\"\n",
    "    # Calculate per-class accuracies\n",
    "    class_acc = class_correct / class_total\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score from confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predicted)\n",
    "    \n",
    "    # Initialize metrics\n",
    "    precision = np.zeros(len(quadrant_names))\n",
    "    recall = np.zeros(len(quadrant_names))\n",
    "    f1_score = np.zeros(len(quadrant_names))\n",
    "    \n",
    "    # Calculate metrics for each class\n",
    "    for i in range(len(quadrant_names)):\n",
    "        tp = cm[i, i]\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        \n",
    "        precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "    \n",
    "    # Create figure for the table\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    ax.axis('off')  # Hide axes\n",
    "    \n",
    "    # Prepare table data\n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Cross-Subject Overall Accuracy', f\"{overall_accuracy:.4f}\"],\n",
    "        ['', ''],  # Empty row for spacing\n",
    "        ['Per-Class Results (Unseen Subjects)', '']\n",
    "    ]\n",
    "    \n",
    "    # Add per-class metrics to the table\n",
    "    for i, name in enumerate(quadrant_names):\n",
    "        table_data.append([f'{name} Accuracy', f\"{class_acc[i]:.4f} ({int(class_correct[i])}/{int(class_total[i])})\"])\n",
    "        table_data.append([f'{name} Precision', f\"{precision[i]:.4f}\"])\n",
    "        table_data.append([f'{name} Recall', f\"{recall[i]:.4f}\"])\n",
    "        table_data.append([f'{name} F1 Score', f\"{f1_score[i]:.4f}\"])\n",
    "        table_data.append(['', ''])  # Empty row for spacing\n",
    "    \n",
    "    # Create the table\n",
    "    table = ax.table(cellText=table_data, loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 1.8)\n",
    "    \n",
    "    # Color header row\n",
    "    for j in range(len(table_data[0])):\n",
    "        table[(0, j)].set_facecolor('#4472C4')\n",
    "        table[(0, j)].set_text_props(color='white')\n",
    "        table[(3, j)].set_facecolor('#70AD47')\n",
    "        table[(3, j)].set_text_props(color='white')\n",
    "    \n",
    "    plt.title('Subject-Independent Performance Metrics\\\\n(Cross-Subject Generalization)', pad=20, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if data_loaded and 'fold_results' in locals():\n",
    "    print(\"Generating 5-fold subject-independent cross-validation summary...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create comprehensive summary plots for subject-independent CV\n",
    "    def plot_subject_indep_cv_summary(all_fold_costs, all_fold_classifier_losses, all_fold_test_accuracies, save_path):\n",
    "        \"\"\"Plot average learning curves across all folds for subject-independent CV\"\"\"\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Calculate average and std across folds\n",
    "        max_len_costs = max(len(costs) for costs in all_fold_costs)\n",
    "        max_len_classifier = max(len(losses) for losses in all_fold_classifier_losses)\n",
    "        max_len_accuracy = max(len(acc) for acc in all_fold_test_accuracies)\n",
    "        \n",
    "        # Pad sequences to same length\n",
    "        padded_costs = []\n",
    "        padded_classifier = []\n",
    "        padded_accuracy = []\n",
    "        \n",
    "        for i in range(len(all_fold_costs)):\n",
    "            costs = all_fold_costs[i] + [all_fold_costs[i][-1]] * (max_len_costs - len(all_fold_costs[i]))\n",
    "            classifier = all_fold_classifier_losses[i] + [all_fold_classifier_losses[i][-1]] * (max_len_classifier - len(all_fold_classifier_losses[i]))\n",
    "            accuracy = all_fold_test_accuracies[i] + [all_fold_test_accuracies[i][-1]] * (max_len_accuracy - len(all_fold_test_accuracies[i]))\n",
    "            \n",
    "            padded_costs.append(costs)\n",
    "            padded_classifier.append(classifier)\n",
    "            padded_accuracy.append(accuracy)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        costs_array = np.array(padded_costs)\n",
    "        classifier_array = np.array(padded_classifier)\n",
    "        accuracy_array = np.array(padded_accuracy)\n",
    "        \n",
    "        # Calculate means and stds\n",
    "        costs_mean = np.mean(costs_array, axis=0)\n",
    "        costs_std = np.std(costs_array, axis=0)\n",
    "        classifier_mean = np.mean(classifier_array, axis=0)\n",
    "        classifier_std = np.std(classifier_array, axis=0)\n",
    "        accuracy_mean = np.mean(accuracy_array, axis=0)\n",
    "        accuracy_std = np.std(accuracy_array, axis=0)\n",
    "        \n",
    "        # Plot MFMC cost with error bars\n",
    "        plt.subplot(2, 2, 1)\n",
    "        x_costs = np.arange(len(costs_mean))\n",
    "        plt.plot(x_costs, costs_mean, 'b-', label='Mean')\n",
    "        plt.fill_between(x_costs, costs_mean - costs_std, costs_mean + costs_std, alpha=0.3)\n",
    "        plt.title('MFMC Loss (5-Fold Average)\\\\nSubject-Independent')\n",
    "        plt.xlabel('Iteration (x100)')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot classifier loss with error bars\n",
    "        plt.subplot(2, 2, 2)\n",
    "        x_classifier = np.arange(len(classifier_mean))\n",
    "        plt.plot(x_classifier, classifier_mean, 'r-', label='Mean')\n",
    "        plt.fill_between(x_classifier, classifier_mean - classifier_std, classifier_mean + classifier_std, alpha=0.3)\n",
    "        plt.title('Classifier Loss (5-Fold Average)\\\\nSubject-Independent')\n",
    "        plt.xlabel('Iteration (x100)')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot cross-subject test accuracy with error bars\n",
    "        plt.subplot(2, 2, 3)\n",
    "        x_accuracy = np.arange(len(accuracy_mean))\n",
    "        plt.plot(x_accuracy, accuracy_mean, 'g-', label='Mean')\n",
    "        plt.fill_between(x_accuracy, accuracy_mean - accuracy_std, accuracy_mean + accuracy_std, alpha=0.3)\n",
    "        plt.title('Cross-Subject Accuracy (5-Fold Average)\\\\nUnseen Subjects')\n",
    "        plt.xlabel(f'Evaluation (x{EVAL_INTERVAL} iterations)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot cross-subject accuracy distribution across folds\n",
    "        plt.subplot(2, 2, 4)\n",
    "        final_accuracies = [result['best_accuracy'] for result in fold_results]\n",
    "        fold_numbers = [result['fold'] for result in fold_results]\n",
    "        \n",
    "        bars = plt.bar(fold_numbers, final_accuracies, alpha=0.7)\n",
    "        plt.axhline(y=np.mean(final_accuracies), color='r', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(final_accuracies):.4f}')\n",
    "        plt.title('Best Cross-Subject Accuracy per Fold\\\\nCompletely Different Subjects')\n",
    "        plt.xlabel('Fold')\n",
    "        plt.ylabel('Cross-Subject Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Color bars based on performance\n",
    "        for i, bar in enumerate(bars):\n",
    "            if final_accuracies[i] >= np.mean(final_accuracies):\n",
    "                bar.set_color('green')\n",
    "            else:\n",
    "                bar.set_color('orange')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # Create detailed subject-independent results table\n",
    "    def plot_subject_indep_results_table(fold_results, save_path):\n",
    "        \"\"\"Create a comprehensive results table for subject-independent CV\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Prepare table data\n",
    "        table_data = [\n",
    "            ['Metric', 'Mean ± Std', 'Min', 'Max'],\n",
    "            ['', '', '', '']  # Empty row\n",
    "        ]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        best_accs = [r['best_accuracy'] for r in fold_results]\n",
    "        final_accs = [r['final_accuracy'] for r in fold_results] \n",
    "        times = [r['training_time'] for r in fold_results]\n",
    "        \n",
    "        metrics = [\n",
    "            ('Cross-Subject Best Accuracy', best_accs),\n",
    "            ('Cross-Subject Final Accuracy', final_accs),\n",
    "            ('Training Time (min)', [t/60 for t in times])\n",
    "        ]\n",
    "        \n",
    "        for metric_name, values in metrics:\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values)\n",
    "            min_val = np.min(values)\n",
    "            max_val = np.max(values)\n",
    "            \n",
    "            if 'Time' in metric_name:\n",
    "                table_data.append([\n",
    "                    metric_name,\n",
    "                    f\"{mean_val:.1f} ± {std_val:.1f}\",\n",
    "                    f\"{min_val:.1f}\",\n",
    "                    f\"{max_val:.1f}\"\n",
    "                ])\n",
    "            else:\n",
    "                table_data.append([\n",
    "                    metric_name,\n",
    "                    f\"{mean_val:.4f} ± {std_val:.4f}\",\n",
    "                    f\"{min_val:.4f}\",\n",
    "                    f\"{max_val:.4f}\"\n",
    "                ])\n",
    "        \n",
    "        # Add fold-specific results with subject information\n",
    "        table_data.append(['', '', '', ''])  # Empty row\n",
    "        table_data.append(['Fold-Specific Results', 'Train Subjects', 'Test Subjects', 'Best Accuracy'])\n",
    "        \n",
    "        for result in fold_results:\n",
    "            train_subj_str = ', '.join(map(str, result['train_subjects'][:3])) + '...' if len(result['train_subjects']) > 3 else ', '.join(map(str, result['train_subjects']))\n",
    "            test_subj_str = ', '.join(map(str, result['test_subjects'][:3])) + '...' if len(result['test_subjects']) > 3 else ', '.join(map(str, result['test_subjects']))\n",
    "            \n",
    "            table_data.append([\n",
    "                f\"Fold {result['fold']}\",\n",
    "                train_subj_str,\n",
    "                test_subj_str,\n",
    "                f\"{result['best_accuracy']:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # Create table\n",
    "        table = ax.table(cellText=table_data, loc='center', cellLoc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1, 2.5)\n",
    "        \n",
    "        # Style header\n",
    "        for j in range(len(table_data[0])):\n",
    "            table[(0, j)].set_facecolor('#4472C4')\n",
    "            table[(0, j)].set_text_props(color='white', weight='bold')\n",
    "            \n",
    "        # Style section headers\n",
    "        for i, row in enumerate(table_data):\n",
    "            if 'Fold-Specific Results' in row[0]:\n",
    "                for j in range(len(row)):\n",
    "                    table[(i, j)].set_facecolor('#70AD47')\n",
    "                    table[(i, j)].set_text_props(color='white', weight='bold')\n",
    "        \n",
    "        plt.title('5-Fold Subject-Independent Cross-Validation Results\\\\nMFMC Cross-Subject Generalization', \n",
    "                 pad=20, fontsize=16, weight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # Generate comprehensive summary plot\n",
    "    plot_subject_indep_cv_summary(all_fold_costs, all_fold_classifier_losses, all_fold_test_accuracies,\n",
    "                                 f'{RESULTS_DIR}/subject_indep_cv_summary.png')\n",
    "    \n",
    "    # Generate detailed results table\n",
    "    plot_subject_indep_results_table(fold_results, f'{RESULTS_DIR}/subject_indep_cv_table.png')\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    cv_results = {\n",
    "        'cv_statistics': {\n",
    "            'cross_subject_best_accuracy_mean': cv_mean_best,\n",
    "            'cross_subject_best_accuracy_std': cv_std_best,\n",
    "            'cross_subject_final_accuracy_mean': cv_mean_final,\n",
    "            'cross_subject_final_accuracy_std': cv_std_final,\n",
    "            'total_cv_time': total_cv_time\n",
    "        },\n",
    "        'fold_results': fold_results,\n",
    "        'all_fold_data': {\n",
    "            'costs': all_fold_costs,\n",
    "            'classifier_losses': all_fold_classifier_losses,\n",
    "            'test_accuracies': all_fold_test_accuracies\n",
    "        },\n",
    "        'config': {\n",
    "            'evaluation_type': 'subject_independent',\n",
    "            'n_folds': N_FOLDS,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'total_iterations_per_fold': TOTAL_ITERATIONS,\n",
    "            'cov_beta': COV_BETA,\n",
    "            'learning_rate_encoder': LEARNING_RATE_ENCODER,\n",
    "            'learning_rate_classifier': LEARNING_RATE_CLASSIFIER,\n",
    "            'use_class_balancing': USE_CLASS_BALANCING,\n",
    "            'random_seed': RANDOM_SEED\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    np.save(f'{RESULTS_DIR}/subject_indep_cv_results.npy', cv_results)\n",
    "    print(f\"Comprehensive subject-independent CV results saved to {RESULTS_DIR}/subject_indep_cv_results.npy\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"SUBJECT-INDEPENDENT 5-FOLD CV MFMC DEMO COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"FINAL SUMMARY (Cross-Subject Generalization):\")\n",
    "    print(f\"Cross-validation completed successfully across different subjects\")\n",
    "    print(f\"Mean cross-subject best accuracy: {cv_mean_best:.4f} ± {cv_std_best:.4f}\")\n",
    "    print(f\"Mean cross-subject final accuracy: {cv_mean_final:.4f} ± {cv_std_final:.4f}\")\n",
    "    print(f\"Total training time: {str(timedelta(seconds=int(total_cv_time)))}\")\n",
    "    print(f\"All visualizations and results saved to: {RESULTS_DIR}\")\n",
    "    print(\"\\\\nGenerated files:\")\n",
    "    print(f\"- Individual fold curves: fold_1_curves.png to fold_{N_FOLDS}_curves.png\")\n",
    "    print(f\"- Subject-independent CV summary: subject_indep_cv_summary.png\")\n",
    "    print(f\"- Results table: subject_indep_cv_table.png\")\n",
    "    print(f\"- Complete results: subject_indep_cv_results.npy\")\n",
    "    print(\"\\\\nKey Achievement:\")\n",
    "    print(\"Demonstrated MFMC's ability to generalize emotion recognition\")\n",
    "    print(\"across completely different individuals (subject-independent)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot perform evaluation - subject-independent cross-validation was not completed or data not loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a17cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
